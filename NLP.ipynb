{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO51KGRwn5+ePvjQrBEh81K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cGwntUkCPzML","executionInfo":{"status":"ok","timestamp":1732607494863,"user_tz":-330,"elapsed":4792,"user":{"displayName":"shahla Shalu","userId":"06849421744657379880"}},"outputId":"f3cf6377-e05d-4e1f-df6f-a6a08b142265"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"slCneO3jOOTU","executionInfo":{"status":"ok","timestamp":1732607494864,"user_tz":-330,"elapsed":25,"user":{"displayName":"shahla Shalu","userId":"06849421744657379880"}},"outputId":"ecaee73a-6c97-4be2-fb5c-914ed32798a6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'me',\n"," 'my',\n"," 'myself',\n"," 'we',\n"," 'our',\n"," 'ours',\n"," 'ourselves',\n"," 'you',\n"," \"you're\",\n"," \"you've\",\n"," \"you'll\",\n"," \"you'd\",\n"," 'your',\n"," 'yours',\n"," 'yourself',\n"," 'yourselves',\n"," 'he',\n"," 'him',\n"," 'his',\n"," 'himself',\n"," 'she',\n"," \"she's\",\n"," 'her',\n"," 'hers',\n"," 'herself',\n"," 'it',\n"," \"it's\",\n"," 'its',\n"," 'itself',\n"," 'they',\n"," 'them',\n"," 'their',\n"," 'theirs',\n"," 'themselves',\n"," 'what',\n"," 'which',\n"," 'who',\n"," 'whom',\n"," 'this',\n"," 'that',\n"," \"that'll\",\n"," 'these',\n"," 'those',\n"," 'am',\n"," 'is',\n"," 'are',\n"," 'was',\n"," 'were',\n"," 'be',\n"," 'been',\n"," 'being',\n"," 'have',\n"," 'has',\n"," 'had',\n"," 'having',\n"," 'do',\n"," 'does',\n"," 'did',\n"," 'doing',\n"," 'a',\n"," 'an',\n"," 'the',\n"," 'and',\n"," 'but',\n"," 'if',\n"," 'or',\n"," 'because',\n"," 'as',\n"," 'until',\n"," 'while',\n"," 'of',\n"," 'at',\n"," 'by',\n"," 'for',\n"," 'with',\n"," 'about',\n"," 'against',\n"," 'between',\n"," 'into',\n"," 'through',\n"," 'during',\n"," 'before',\n"," 'after',\n"," 'above',\n"," 'below',\n"," 'to',\n"," 'from',\n"," 'up',\n"," 'down',\n"," 'in',\n"," 'out',\n"," 'on',\n"," 'off',\n"," 'over',\n"," 'under',\n"," 'again',\n"," 'further',\n"," 'then',\n"," 'once',\n"," 'here',\n"," 'there',\n"," 'when',\n"," 'where',\n"," 'why',\n"," 'how',\n"," 'all',\n"," 'any',\n"," 'both',\n"," 'each',\n"," 'few',\n"," 'more',\n"," 'most',\n"," 'other',\n"," 'some',\n"," 'such',\n"," 'no',\n"," 'nor',\n"," 'not',\n"," 'only',\n"," 'own',\n"," 'same',\n"," 'so',\n"," 'than',\n"," 'too',\n"," 'very',\n"," 's',\n"," 't',\n"," 'can',\n"," 'will',\n"," 'just',\n"," 'don',\n"," \"don't\",\n"," 'should',\n"," \"should've\",\n"," 'now',\n"," 'd',\n"," 'll',\n"," 'm',\n"," 'o',\n"," 're',\n"," 've',\n"," 'y',\n"," 'ain',\n"," 'aren',\n"," \"aren't\",\n"," 'couldn',\n"," \"couldn't\",\n"," 'didn',\n"," \"didn't\",\n"," 'doesn',\n"," \"doesn't\",\n"," 'hadn',\n"," \"hadn't\",\n"," 'hasn',\n"," \"hasn't\",\n"," 'haven',\n"," \"haven't\",\n"," 'isn',\n"," \"isn't\",\n"," 'ma',\n"," 'mightn',\n"," \"mightn't\",\n"," 'mustn',\n"," \"mustn't\",\n"," 'needn',\n"," \"needn't\",\n"," 'shan',\n"," \"shan't\",\n"," 'shouldn',\n"," \"shouldn't\",\n"," 'wasn',\n"," \"wasn't\",\n"," 'weren',\n"," \"weren't\",\n"," 'won',\n"," \"won't\",\n"," 'wouldn',\n"," \"wouldn't\"]"]},"metadata":{},"execution_count":2}],"source":["from nltk.corpus import stopwords\n","stopwordss = stopwords.words('english')\n","stopwordss"]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt_tab')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3x8MVj_0QkO_","executionInfo":{"status":"ok","timestamp":1732607494864,"user_tz":-330,"elapsed":21,"user":{"displayName":"shahla Shalu","userId":"06849421744657379880"}},"outputId":"4dba61e3-fa38-4a2e-da27-4d0080a9499b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["sentence = \"This is my first sentence. A basic sentence.\"\n","tokens = nltk.word_tokenize(sentence)\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_I3kvMuQQym","executionInfo":{"status":"ok","timestamp":1732607494864,"user_tz":-330,"elapsed":16,"user":{"displayName":"shahla Shalu","userId":"06849421744657379880"}},"outputId":"44f63b7d-aa61-47f2-e7f2-e171e6696886"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['This', 'is', 'my', 'first', 'sentence', '.', 'A', 'basic', 'sentence', '.']"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","sentence = \"at Eight o clock on Tuesday Morning, Hello How are you!!\"\n","\n","stopwordss = set(stopwords.words(\"english\"))\n","tokens = word_tokenize(sentence)\n","tokens\n","\n","words = [w for w in tokens if not w in stopwordss]\n","words"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eeglDBWZRkql","executionInfo":{"status":"ok","timestamp":1732607494864,"user_tz":-330,"elapsed":13,"user":{"displayName":"shahla Shalu","userId":"06849421744657379880"}},"outputId":"9d339dd7-191f-4afb-831b-14c3949eeb23"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Eight', 'clock', 'Tuesday', 'Morning', ',', 'Hello', 'How', '!', '!']"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","sentence = \"at eight o clock on tuesday morning, hello how are you!!\"\n","\n","stopwordss = set(stopwords.words(\"english\"))\n","tokens = word_tokenize(sentence)\n","tokens\n","\n","words = [w.lower() for w in tokens if not w in stopwordss]\n","words"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VoOanuU_S_qr","executionInfo":{"status":"ok","timestamp":1732607494864,"user_tz":-330,"elapsed":10,"user":{"displayName":"shahla Shalu","userId":"06849421744657379880"}},"outputId":"3978274a-bcf9-4d70-c00d-bf22a0ffc70e"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['eight', 'clock', 'tuesday', 'morning', ',', 'hello', '!', '!']"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["\n","\n","```\n","this is not good\n","\n","this, is, not, good\n","\n","\n","# ngrams\n","\n","ngram = 1  ngram = 2  ngram = 3\n","this       this is     this is not\n","\n","is       is not        is not good\n","\n","not     not good\n","\n","good\n","\n","```\n","\n"],"metadata":{"id":"iU9Wwz6MUPmP"}},{"source":["from nltk.util import ngrams\n","import nltk\n","\n","sentence = \"at Eight o clock on Tuesday Morning, Hello How are you!!\"\n","\n","# Pass the tokenized sentence as the first positional argument\n","Ngrams = ngrams(nltk.word_tokenize(sentence), n=3)\n","\n","for grams in Ngrams:\n","  print(grams)"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p613HfYkXoEr","executionInfo":{"status":"ok","timestamp":1732607495382,"user_tz":-330,"elapsed":19,"user":{"displayName":"shahla Shalu","userId":"06849421744657379880"}},"outputId":"2789ae79-e0b0-49f5-8841-856dd9177516"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["('at', 'Eight', 'o')\n","('Eight', 'o', 'clock')\n","('o', 'clock', 'on')\n","('clock', 'on', 'Tuesday')\n","('on', 'Tuesday', 'Morning')\n","('Tuesday', 'Morning', ',')\n","('Morning', ',', 'Hello')\n","(',', 'Hello', 'How')\n","('Hello', 'How', 'are')\n","('How', 'are', 'you')\n","('are', 'you', '!')\n","('you', '!', '!')\n"]}]},{"cell_type":"markdown","source":["# **Stemming**"],"metadata":{"id":"WbkYDFWLX0rU"}},{"cell_type":"code","source":["from nltk.stem import SnowballStemmer\n","\n","sb = SnowballStemmer('english')\n","\n","words = ['eight', 'clock', 'program', 'programs', 'programmer', 'programming', 'thursday', 'morning', ',', 'hello']\n","\n","for w in words:\n","         print(w, \",\", sb.stem(w))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sUy9FBsXWWoQ","executionInfo":{"status":"ok","timestamp":1732607495382,"user_tz":-330,"elapsed":16,"user":{"displayName":"shahla Shalu","userId":"06849421744657379880"}},"outputId":"8b7b6b85-0ab5-45e4-b24f-bbf4a2fa68c8"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["eight , eight\n","clock , clock\n","program , program\n","programs , program\n","programmer , programm\n","programming , program\n","thursday , thursday\n","morning , morn\n",", , ,\n","hello , hello\n"]}]},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","\n","porter = PorterStemmer()\n","\n","words = ['eight', 'clock', 'program', 'programs', 'programmer', 'programming', 'thursday', 'morning', ',', 'hello']\n","\n","print(\"Word, Porter Stem\")\n","\n","for w in words:\n","  print(w, \",\", porter.stem(w))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ux47hOGYma9","executionInfo":{"status":"ok","timestamp":1732607495382,"user_tz":-330,"elapsed":13,"user":{"displayName":"shahla Shalu","userId":"06849421744657379880"}},"outputId":"2acef63c-83e4-44d5-cee6-03a094eb310d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Word, Porter Stem\n","eight , eight\n","clock , clock\n","program , program\n","programs , program\n","programmer , programm\n","programming , program\n","thursday , thursday\n","morning , morn\n",", , ,\n","hello , hello\n"]}]},{"cell_type":"markdown","source":["# **Lemmatization**"],"metadata":{"id":"GUQYfMHHcoml"}},{"cell_type":"code","source":["import nltk\n","nltk.download('wordnet')\n","\n","from nltk.stem import WordNetLemmatizer\n","\n","lem = WordNetLemmatizer()\n","\n","print(\"rocks\", lem.lemmatize('rocks'))\n","\n","print('thought', lem.lemmatize('thought'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgkIDzDhZfMf","executionInfo":{"status":"ok","timestamp":1732607510518,"user_tz":-330,"elapsed":15146,"user":{"displayName":"shahla Shalu","userId":"06849421744657379880"}},"outputId":"9721eeec-fe6d-4f30-e2f9-63ed4e3039b0"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["rocks rock\n","thought thought\n"]}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","\n","len = WordNetLemmatizer()\n","\n","# Lemmatize as nouns (default behavior)\n","\n","print('rocks as noun:', lem.lemmatize('rocks'))\n","print('thought as noun:', len.lemmatize('thought'))\n","\n","# Lemmatize as verbs\n","\n","print('rocks as verb:', lem.lemmatize('rocks', pos='v'))\n","print('thought as verb:', len.lemmatize('thought', pos='v'))\n","print('played as verb:', lem. lemmatize('played', pos='v'))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IH-dglVHa8Fs","executionInfo":{"status":"ok","timestamp":1732607510518,"user_tz":-330,"elapsed":14,"user":{"displayName":"shahla Shalu","userId":"06849421744657379880"}},"outputId":"10ea711c-b8f0-47af-f20a-92d1e4aac4f1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["rocks as noun: rock\n","thought as noun: thought\n","rocks as verb: rock\n","thought as verb: think\n","played as verb: play\n"]}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","\n","lem = WordNetLemmatizer()\n","\n","# Lemnatize words with different POS tags\n","\n","print('rocks as noun:', lem.lemmatize('rocks', pos='n')) # Noun\n","print('rocks as verb:', lem.lemmatize('rocks', pos='v')) # Verb\n","print('better as adjective:', lem.lemmatize('better', pos='a')) # Adjective\n","print('better as adverb:', lem.lemmatize('better', pos='r')) # Adverb\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"joVBhXWWbhVI","executionInfo":{"status":"ok","timestamp":1732607510518,"user_tz":-330,"elapsed":13,"user":{"displayName":"shahla Shalu","userId":"06849421744657379880"}},"outputId":"1ea825a1-0c87-4758-b723-c6e93e5f3430"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["rocks as noun: rock\n","rocks as verb: rock\n","better as adjective: good\n","better as adverb: well\n"]}]}]}